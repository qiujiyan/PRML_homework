{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from multiprocessing import Pool\n",
    "from tabulate import tabulate\n",
    "\n",
    "class NaiveBayesKDE:\n",
    "    def __init__(self, kernel='gaussian', bandwidth=1.0):\n",
    "        self.kernel = kernel\n",
    "        self.bandwidth = bandwidth\n",
    "        self.training_data = None\n",
    "        self.labels = None\n",
    "\n",
    "    def _kernel_function(self, x):\n",
    "        if self.kernel == 'hypercube':\n",
    "            return np.all(np.abs(x) <= 0.5, axis=1)\n",
    "        elif self.kernel == 'gaussian':\n",
    "            return norm.pdf(x, scale=self.bandwidth)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.training_data = X\n",
    "        self.labels = y\n",
    "\n",
    "    def _estimate_density(self, x):\n",
    "        densities = []\n",
    "        for label in np.unique(self.labels):\n",
    "            class_data = self.training_data[self.labels == label]\n",
    "            distances = (x - class_data) / self.bandwidth\n",
    "            kernel_values = self._kernel_function(distances)\n",
    "            density = np.mean(kernel_values, axis=0)\n",
    "            densities.append(density)\n",
    "        return np.array(densities)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            densities = self._estimate_density(x)\n",
    "            predicted_label = np.argmax(densities)\n",
    "            predictions.append(predicted_label)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    # Additional methods for multiprocessing and hyperparameter tuning can be added here\n",
    "\n",
    "# Example usage\n",
    "# classifier = NaiveBayesKDE(kernel='gaussian', bandwidth=1.0)\n",
    "# classifier.fit(training_data, training_labels)\n",
    "# predictions = classifier.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    \"\"\"\n",
    "    A Naive Bayes Classifier using Kernel Density Estimation with Parzen windows.\n",
    "\n",
    "    The classifier implements two kernels for parzen window  - Radial and Hypercube\n",
    "\n",
    "    It also implements Single bandwidth model and class-specific Multi bandwidth model\n",
    "\n",
    "    The kernel and model type are passed as arguments to class object initialization.\n",
    "\n",
    "    Along with the number of bandwidths necessary, in case of Multi bandwidth model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bandwidth=1, kernel='radial', multi_bw=False):\n",
    "        \"\"\"\n",
    "        Initialize the classifier with proper parameters.\n",
    "\n",
    "        :param bandwidth: An integer giving the number of bandwidths necessary\n",
    "        :param kernel: A string specifying the kernel to be used for the model\n",
    "        :param multi_bw: A boolean variable specifying if the Multi bandwidth\n",
    "                        model is to be used.\n",
    "                        By default Single bandwidth model is selected.\n",
    "        \"\"\"\n",
    "        self.priors = dict()\n",
    "        self.dim = 1\n",
    "        self.multi_bw = multi_bw\n",
    "        self.bandwidth = bandwidth\n",
    "        if kernel == \"radial\":\n",
    "            self.kernel = self.radial\n",
    "        elif kernel == \"hypercube\":\n",
    "            self.kernel = self.hypercube\n",
    "\n",
    "    def hypercube(self, k):\n",
    "        \"\"\"\n",
    "        Hypercube kernel for Density Estimation.\n",
    "        \"\"\"\n",
    "        return np.all(k < 0.5, axis=1)\n",
    "\n",
    "    def radial(self, k):\n",
    "        \"\"\"\n",
    "        Radial Kernel for Density estimation.\n",
    "        \"\"\"\n",
    "        const_part = (2 * np.pi) ** (-self.dim / 2)\n",
    "        return const_part * np.exp(-0.5 * np.add.reduce(k ** 2, axis=1))\n",
    "\n",
    "    def parzen_estimation(self, h, x, x_train):\n",
    "        \"\"\"\n",
    "        Density estimation for a single sample against the training set with\n",
    "        parzen window using the specified bandwidth, kernel.\n",
    "\n",
    "        :param h: An integer value giving the bandwidth to be used for the class.\n",
    "        :param x: A single input sample, whose density needs to be estimated.\n",
    "        :param x_train: Array of input data to calculate KDE value against.\n",
    "        :return: A single float value giving the density of the function at the given point.\n",
    "        \"\"\"\n",
    "        N = x_train.shape[0]\n",
    "        dim = self.dim\n",
    "        k = np.abs(x - x_train) * 1.0 / h\n",
    "        summation = np.add.reduce(self.kernel(k))\n",
    "        return summation / (N * (h ** dim))\n",
    "\n",
    "    def KDE(self, h, x_test, x_train):\n",
    "        \"\"\"\n",
    "        Kernel Density Estimation based on the parameters set.\n",
    "\n",
    "        :param h: An integer value giving the bandwidth to be used for the class.\n",
    "        :param x_test: Array of input data to make predictions.\n",
    "        :param x_train: Array of input data to calculate KDE value against.\n",
    "        :return: A list of floats giving the density estimation values for each\n",
    "                 row in x_test, x_test[i] calculated against the training set, previously set\n",
    "        \"\"\"\n",
    "        P_x = np.zeros(len(x_test))\n",
    "        N = x_train.shape[0]\n",
    "        dim = self.dim\n",
    "        for i in range(len(x_test)):\n",
    "            P_x[i] = self.parzen_estimation(h, x_test[i], x_train)\n",
    "\n",
    "        return P_x\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fits the model to the training set.\n",
    "        Since KDE is a lazy learner we just need to save the necessary information.\n",
    "\n",
    "        :param X: Array of input data\n",
    "        :param Y: Array of output labels\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.x_train = X\n",
    "        self.y_train = Y\n",
    "        self.dim = X.shape[1]\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            self.priors[c] = float(len(Y[Y == c])) / len(Y)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Predict the labels of testing set, using KDE.\n",
    "\n",
    "        :param x_test: Array of input data to make predictions.\n",
    "        :return: Predicted labels of the data.\n",
    "        \"\"\"\n",
    "        N, D = x_test.shape\n",
    "        priors = self.priors\n",
    "        K = len(priors)\n",
    "        P = np.zeros((N, K))\n",
    "        x_train = self.x_train\n",
    "        y_train = self.y_train\n",
    "        if self.multi_bw:\n",
    "            bw = self.bandwidth\n",
    "        else:\n",
    "            bw = np.repeat(self.bandwidth, K)\n",
    "        for c, p in priors.items():\n",
    "            P[:, int(c)] = self.KDE(bw[int(c)], x_test, x_train[y_train == c]) * p\n",
    "\n",
    "        pred_y = np.argmax(P, axis=1)\n",
    "        self.pred_y = pred_y\n",
    "\n",
    "        return pred_y\n",
    "\n",
    "    def accuracy(self, y_test):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy between the predicted label and actual labels.\n",
    "\n",
    "        :param y_test: Array of actual output labels of Testing set.\n",
    "        :return: A float value giving the accuracy.\n",
    "        \"\"\"\n",
    "        pred_y = self.pred_y\n",
    "        return np.array([pred_y == y_test]).mean()\n",
    "\n",
    "    def score(self, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Function that runs both Predict and Accuracy and returns the accuracy\n",
    "        score of the model.\n",
    "\n",
    "        :param x_test: Array of input data to make predictions.\n",
    "        :param y_test: Array of actual output labels of Testing set.\n",
    "        :return: A float value giving the accuracy of the model.\n",
    "        \"\"\"\n",
    "        self.predict(x_test)\n",
    "        return self.accuracy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_iris\n",
      "0.974 0.974 0.974 0.974 0.974 0.974 0.974 0.974 0.947 0.921 \n",
      "load_iris\n",
      "1.000 1.000 0.974 0.974 0.974 0.974 0.974 0.974 0.974 0.947 \n",
      "load_digits\n",
      "0.082 0.082 0.113 0.318 0.687 0.893 0.969 0.991 0.991 0.991 \n",
      "load_digits\n",
      "0.118 0.118 0.164 0.358 0.711 0.927 0.984 0.989 0.989 0.989 \n",
      "load_breast_cancer\n",
      "0.371 0.427 0.538 0.713 0.818 0.860 0.888 0.902 0.923 0.923 \n",
      "load_breast_cancer\n",
      "0.385 0.462 0.643 0.825 0.909 0.923 0.930 0.944 0.944 0.944 \n",
      "load_digits\n",
      "0.082 0.082 0.113 0.318 0.687 0.893 0.969 0.991 0.991 0.991 \n",
      "load_digits\n",
      "0.118 0.118 0.164 0.358 0.711 0.927 0.984 0.989 0.989 0.989 \n",
      "load_wine\n",
      "0.422 0.578 0.733 0.733 0.689 0.733 0.733 0.733 0.733 0.756 \n",
      "load_wine\n",
      "0.400 0.489 0.622 0.711 0.689 0.689 0.689 0.689 0.689 0.711 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "all_res = []\n",
    "for f in [load_iris,load_digits,load_breast_cancer,load_wine]:\n",
    "    dataset = f()\n",
    "    icv_res=[]\n",
    "    for cv in range(2):\n",
    "        # np.random.shuffle(dataset)\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(dataset.data,dataset.target ,train_size=0.75, random_state=cv)\n",
    "        print(f.__name__)\n",
    "        # print(X_train.shape , X_test.shape, len(np.unique(y_train)))\n",
    "        result = []\n",
    "\n",
    "        for j in np.linspace(0.1,1,10):\n",
    "            model = NaiveBayesClassifier(bandwidth=j)\n",
    "            model.fit(X_train,y_train)\n",
    "            predict_y = model.predict(X_test)\n",
    "            acc = accuracy_score(predict_y,y_test)\n",
    "            result.append(acc)\n",
    "            print( \"%3.3f\"%acc,end=\" \")\n",
    "        print(\"\")\n",
    "        icv_res.append(result)\n",
    "    icv_res = np.array(icv_res)\n",
    "    icv_res = icv_res.mean(axis=0)\n",
    "    all_res.append(icv_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41111111, 0.53333333, 0.67777778, 0.72222222, 0.68888889,\n",
       "       0.71111111, 0.71111111, 0.71111111, 0.71111111, 0.73333333])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.98684211, 0.98684211, 0.97368421, 0.97368421, 0.97368421,\n",
       "        0.97368421, 0.97368421, 0.97368421, 0.96052632, 0.93421053]),\n",
       " array([0.1       , 0.1       , 0.13888889, 0.33777778, 0.69888889,\n",
       "        0.91      , 0.97666667, 0.99      , 0.99      , 0.99      ]),\n",
       " array([0.37762238, 0.44405594, 0.59090909, 0.76923077, 0.86363636,\n",
       "        0.89160839, 0.90909091, 0.92307692, 0.93356643, 0.93356643]),\n",
       " array([0.1       , 0.1       , 0.13888889, 0.33777778, 0.69888889,\n",
       "        0.91      , 0.97666667, 0.99      , 0.99      , 0.99      ]),\n",
       " array([0.41111111, 0.53333333, 0.67777778, 0.72222222, 0.68888889,\n",
       "        0.71111111, 0.71111111, 0.71111111, 0.71111111, 0.73333333])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_1d = [x[0] for x in all_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.986842105263158,\n",
       "  0.986842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9736842105263158,\n",
       "  0.9605263157894737,\n",
       "  0.9342105263157894],\n",
       " [0.1,\n",
       "  0.1,\n",
       "  0.1388888888888889,\n",
       "  0.33777777777777773,\n",
       "  0.6988888888888889,\n",
       "  0.9099999999999999,\n",
       "  0.9766666666666667,\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " [0.3776223776223776,\n",
       "  0.44405594405594406,\n",
       "  0.5909090909090908,\n",
       "  0.7692307692307693,\n",
       "  0.8636363636363636,\n",
       "  0.8916083916083917,\n",
       "  0.9090909090909092,\n",
       "  0.9230769230769231,\n",
       "  0.9335664335664335,\n",
       "  0.9335664335664335],\n",
       " [0.1,\n",
       "  0.1,\n",
       "  0.1388888888888889,\n",
       "  0.33777777777777773,\n",
       "  0.6988888888888889,\n",
       "  0.9099999999999999,\n",
       "  0.9766666666666667,\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " [0.4111111111111111,\n",
       "  0.5333333333333333,\n",
       "  0.6777777777777778,\n",
       "  0.7222222222222222,\n",
       "  0.6888888888888889,\n",
       "  0.711111111111111,\n",
       "  0.711111111111111,\n",
       "  0.711111111111111,\n",
       "  0.711111111111111,\n",
       "  0.7333333333333334]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array(all_res).tolist()\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      " h       &   0.100 &   0.200 &   0.300 &   0.400 &   0.500 &   0.600 &   0.700 &   0.800 &   0.900 &   1.000 \\\\\n",
      "\\midrule\n",
      " dataset &   0.987 &   0.987 &   0.974 &   0.974 &   0.974 &   0.974 &   0.974 &   0.974 &   0.961 &   0.934 \\\\\n",
      " dataset &   0.1   &   0.1   &   0.139 &   0.338 &   0.699 &   0.91  &   0.977 &   0.99  &   0.99  &   0.99  \\\\\n",
      " dataset &   0.378 &   0.444 &   0.591 &   0.769 &   0.864 &   0.892 &   0.909 &   0.923 &   0.934 &   0.934 \\\\\n",
      " dataset &   0.1   &   0.1   &   0.139 &   0.338 &   0.699 &   0.91  &   0.977 &   0.99  &   0.99  &   0.99  \\\\\n",
      " dataset &   0.411 &   0.533 &   0.678 &   0.722 &   0.689 &   0.711 &   0.711 &   0.711 &   0.711 &   0.733 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "tt = [['dataset']+x for x in t]\n",
    "\n",
    "latex_table = tabulate(tt, headers=['h']+[\"%3.3f\"%i for i in np.linspace(0.1,1,10).tolist()] , tablefmt='latex_booktabs' ,floatfmt=\".3g\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataress = [[0.986842105263158,\n",
    "  0.986842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9736842105263158,\n",
    "  0.9605263157894737,\n",
    "  0.9342105263157894],\n",
    " [0.1,\n",
    "  0.1,\n",
    "  0.1388888888888889,\n",
    "  0.33777777777777773,\n",
    "  0.6988888888888889,\n",
    "  0.9099999999999999,\n",
    "  0.9766666666666667,\n",
    "  0.99,\n",
    "  0.99,\n",
    "  0.99],\n",
    " [0.3776223776223776,\n",
    "  0.44405594405594406,\n",
    "  0.5909090909090908,\n",
    "  0.7692307692307693,\n",
    "  0.8636363636363636,\n",
    "  0.8916083916083917,\n",
    "  0.9090909090909092,\n",
    "  0.9230769230769231,\n",
    "  0.9335664335664335,\n",
    "  0.9335664335664335],\n",
    " [0.4111111111111111,\n",
    "  0.5333333333333333,\n",
    "  0.6777777777777778,\n",
    "  0.7222222222222222,\n",
    "  0.6888888888888889,\n",
    "  0.711111111111111,\n",
    "  0.711111111111111,\n",
    "  0.711111111111111,\n",
    "  0.711111111111111,\n",
    "  0.7333333333333334]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
